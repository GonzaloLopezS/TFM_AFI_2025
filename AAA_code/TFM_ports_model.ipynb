{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Puertos de USA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of CSV files to import\n",
    "csv_files = [\n",
    "    '../sources/CBP_drug_seizures/nationwide-drugs-fy19-fy22.csv',\n",
    "    '../sources/CBP_drug_seizures/nationwide-drugs-fy20-fy23.csv',\n",
    "    '../sources/CBP_drug_seizures/nationwide-drugs-fy21-fy24.csv',\n",
    "    '../sources/CBP_drug_seizures/nationwide-drugs-fy22-fy25-dec.csv'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "drug_seizures_dataframes = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto de Los Angeles y Long Beach\n",
    "Alternativas: Seattle/Tacoma, Oakland/San Francisco, Savannah, Miami/Fort Lauderdale, Houston/Galveston, NY/NJ\n",
    "\n",
    "Viendo un poco los puertos con más tráfico de barcos (y de contenedores), tiene sentido trabajar con los puertos mencionados\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar datos de Long Beach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar datos de 'Stats - TEU Archive Since 1995 - NEW.xls'\n",
    "teu_data_long_beach = pd.read_excel('../sources/Stats - TEU Archive Since 1995 - NEW.xls', header=0, nrows=76)\n",
    "teu_data_long_beach['Date'] = pd.to_datetime(teu_data_long_beach['Date'], format='%b %Y').dt.strftime('%Y-%m')\n",
    "\n",
    "teu_data_long_beach.drop(1, inplace=True)\n",
    "teu_data_long_beach.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importar datos del Puerto de Los Ángeles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Date', 'Loaded Imports', 'Empty Imports','Total Imports', 'Loaded Exports', 'Empty Exports', 'Total Exports', 'Total TEUs','Prior Year Change']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of URLs to scrape\n",
    "urls = [\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2024',\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2023',\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2022',\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2021',\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2020',\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2019',\n",
    "    'https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2018'\n",
    "]\n",
    "\n",
    "# Initialize an empty list to store dataframes\n",
    "dataframes = []\n",
    "\n",
    "for url in urls:\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Find the table container\n",
    "    table_container = soup.find('div', class_='table-container')\n",
    "    \n",
    "    # Extract the table rows\n",
    "    rows = table_container.find_all('tr')\n",
    "    \n",
    "    # Extract the table headers\n",
    "    # headers = [header.text.strip() for header in rows[0].find_all('th')]\n",
    "    \n",
    "    # Extract the table data\n",
    "    data = []\n",
    "    for row in rows[1:]:\n",
    "        cols = row.find_all('td')\n",
    "        data.append([col.text.strip() for col in cols])\n",
    "    \n",
    "    # Create a pandas dataframe\n",
    "    df = pd.DataFrame(data, columns=headers)\n",
    "    df.drop(columns=['Prior Year Change'], inplace=True)\n",
    "    df['Date'] = df['Date'] + '_' + url.split('-')[-1]\n",
    "    \n",
    "    # Append the dataframe to the list\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "teu_data_los_angeles = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_data_los_angeles = teu_data_los_angeles[~teu_data_los_angeles['Date'].str.contains('Total Calendar Year|Total Fiscal Year')]\n",
    "teu_data_los_angeles.reset_index(drop=True, inplace=True)\n",
    "indices_to_drop = [12,25,38,51,64,77,90]\n",
    "teu_data_los_angeles.drop(indices_to_drop, inplace=True)\n",
    "teu_data_los_angeles.reset_index(drop=True, inplace=True)\n",
    "teu_data_los_angeles['Date'] = pd.to_datetime(teu_data_los_angeles['Date'], format='%B_%Y').dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to float\n",
    "columns_to_convert = ['Loaded Imports', 'Empty Imports', 'Total Imports', 'Loaded Exports', 'Empty Exports', 'Total Exports', 'Total TEUs']\n",
    "\n",
    "for col in columns_to_convert:\n",
    "    # Remove any commas that might be present in the numbers\n",
    "    teu_data_los_angeles[col] = teu_data_los_angeles[col].astype(str).apply(\n",
    "        lambda x: x.replace('.', '_').replace('_', '', x.count('_')-1).replace('_', '.') if x.count('.') > 1 else x\n",
    "    )\n",
    "    # Then remove any commas and convert to float\n",
    "    teu_data_los_angeles[col] = teu_data_los_angeles[col].str.replace(',', '').astype(float)\n",
    "\n",
    "teu_data_los_angeles.sort_values(by='Date', inplace=True, ascending=False)\n",
    "teu_data_los_angeles.reset_index(drop=True, inplace=True)\n",
    "teu_data_los_angeles.drop(list(range(75,len(teu_data_los_angeles))), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_data_los_angeles.sort_values(by='Date', inplace=True)\n",
    "teu_data_long_beach.sort_values(by='Date', inplace=True)\n",
    "\n",
    "teu_data_los_angeles.reset_index(drop=True, inplace=True)\n",
    "teu_data_long_beach.reset_index(drop=True, inplace=True)\n",
    "\n",
    "combined_teu_data = pd.DataFrame({\n",
    "    'Date': teu_data_los_angeles['Date'],\n",
    "    'Loaded Imports': teu_data_los_angeles['Loaded Imports'] + teu_data_long_beach['Loaded Inbound'],\n",
    "    'Empty Imports': teu_data_los_angeles['Empty Imports'] + teu_data_long_beach['Empty Inbound'],\n",
    "    'Total Imports': teu_data_los_angeles['Total Imports'] + teu_data_long_beach['Loaded Inbound'] + teu_data_long_beach['Empty Inbound'],\n",
    "    'Loaded Exports': teu_data_los_angeles['Loaded Exports'] + teu_data_long_beach['Loaded Outbound'],\n",
    "    'Empty Exports': teu_data_los_angeles['Empty Exports'] + teu_data_long_beach['Empty Outbound'],\n",
    "    'Total Exports': teu_data_los_angeles['Total Exports'] + teu_data_long_beach['Loaded Outbound'] + teu_data_long_beach['Empty Outbound'],\n",
    "    'Total TEUs': teu_data_los_angeles['Total TEUs'] + teu_data_long_beach['Total']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Revisar si los datos de TEU son en unidades o en miles de unidades u otro\n",
    "- Inbound = Importaciones, Outbound = Exportaciones\n",
    "- Asegurarse de que se tienen 75 registros en ambos dataframes y sumarlos\n",
    "- Más adelante se podrían incluir las coordenadas (en caso de incluir otros hubs portuarios)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluir datos de hub_porturario + drug_seizures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Filter the dataframe for 'Los Angeles Field Office'\n",
    "    df_filtered = df[df['Area of Responsibility'] == 'LOS ANGELES FIELD OFFICE']\n",
    "    \n",
    "    # Append the filtered dataframe to the list\n",
    "    drug_seizures_dataframes.append(df_filtered)\n",
    "\n",
    "# Concatenate all filtered dataframes into a single dataframe\n",
    "drug_seizures_combined = pd.concat(drug_seizures_dataframes, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "drug_seizures_combined.drop_duplicates(inplace=True)\n",
    "drug_seizures_combined = drug_seizures_combined.loc[drug_seizures_combined['Area of Responsibility'] == 'LOS ANGELES FIELD OFFICE']\n",
    "drug_seizures_combined.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_seizures_combined.drop(columns=['FY', 'Month (abbv)'], inplace=True)\n",
    "drug_seizures_combined.drop(columns=['Component', 'Region', 'Land Filter', 'Area of Responsibility'], inplace=True)\n",
    "drug_seizures_combined['Date'] = pd.to_datetime(drug_seizures_combined['Date']).dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdataframe = drug_seizures_combined[['Drug Type', 'Count of Event', 'Sum Qty (lbs)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drug_seizures_wide = pd.pivot_table(drug_seizures_combined, index='Date', columns='Drug Type', values=['Count of Event', 'Sum Qty (lbs)'], aggfunc='sum')\n",
    "drug_seizures_wide.columns = ['_'.join(col).strip() for col in drug_seizures_wide.columns.values]\n",
    "drug_seizures_wide.reset_index(inplace=True)\n",
    "drug_seizures_wide['Sum_of_Counts'] = drug_seizures_wide.filter(like='Count of Event_').sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the dates for 'October', 'November', and 'December' by anticipating one year\n",
    "def adjust_fiscal_year(date_str):\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m')\n",
    "    if date.month in [10, 11, 12]:\n",
    "        date = date + pd.DateOffset(years=-1)\n",
    "    return date.strftime('%Y-%m')\n",
    "\n",
    "# Apply the adjustment to the 'Date' column in combined_teu_data\n",
    "drug_seizures_wide['Date'] = drug_seizures_wide['Date'].apply(adjust_fiscal_year)\n",
    "drug_seizures_wide.sort_values(by='Date', ascending=True, inplace=True)\n",
    "drug_seizures_wide.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combinar datos de cargamentos en los puertos del Área de Los Ángeles con las incautaciones de drogas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLA_data = pd.merge(combined_teu_data, drug_seizures_wide, on='Date', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportar el dataframe creado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLA_data.to_csv('../sources/GreaterLosAngeles_data.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLA_data['Computed_Value'] = abs((GLA_data['Total Imports'] + GLA_data['Total Exports']) - GLA_data['Total TEUs'])\n",
    "GLA_data[['Date', 'Computed_Value']].sort_values(by='Computed_Value', ascending=False).head(5)\n",
    "GLA_data.drop(columns=['Computed_Value'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importar datos Gran Los Angeles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLA_data = pd.read_csv('../sources/GreaterLosAngeles_data.csv', sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuperar el dataframe original, añadir columna 'Los Angeles' y sus coordenadas (es posible considerar incluir la población)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_port_hubs = pd.read_csv('../sources/ais_noaa_gov/us_port_hubs.csv')\n",
    "us_port_hubs.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_port_drugs = GLA_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLA_data.drop(columns=['Computed_Value'], inplace=True)\n",
    "GLA_data['latitude'] = us_port_hubs.loc[3, 'coord_0']\n",
    "GLA_data['longitude'] = us_port_hubs.loc[3, 'coord_1']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion de los datos\n",
    "- Limpieza de datos.\n",
    "- Transformación, Normalización de los datos.Integración.\n",
    "- Missing Values.\n",
    "- Outliers & Noise Identification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representacion Grafica de variables y comparacion entre variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En GLA_data existia un error de formato en la observación 25, por lo que, tras arreglarlo más bajo, es necesario volver a ejecutar las celdas de transformación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "# Ensure 'Date' is in datetime format\n",
    "GLA_data['Date'] = pd.to_datetime(GLA_data['Date'])\n",
    "\n",
    "# Identify numeric and categorical columns (excluding 'Date')\n",
    "numeric_features = GLA_data.select_dtypes(include=['float64']).columns\n",
    "categorical_features = GLA_data.select_dtypes(include=['object']).columns\n",
    "\n",
    "# Create transformers for numeric and categorical features\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Exclude 'Date' from transformations\n",
    "features_to_transform = [col for col in GLA_data.columns if col not in ['Date']]\n",
    "\n",
    "# Combine transformers into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Create the final pipeline\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "# Fit and transform the data (excluding 'Date')\n",
    "GLA_data_transformed = pipeline.fit_transform(GLA_data[features_to_transform])\n",
    "\n",
    "# Reconstruct DataFrame\n",
    "transformed_columns = list(numeric_features)\n",
    "if len(categorical_features) > 0:\n",
    "    transformed_columns += list(pipeline.named_steps['preprocessor'].named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features))\n",
    "\n",
    "GLA_data_transformed_df = pd.DataFrame(GLA_data_transformed, columns=transformed_columns)\n",
    "\n",
    "# Reattach 'Date' column\n",
    "GLA_data_transformed_df.insert(0, 'Date', GLA_data['Date'].values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ha corroborado que (Sum Imports + Sum Exports) = TEUs Total se cumple en la mayoría de los casos.\n",
    "Falla para el índice 25 (noviembre-2020) que es el dato tratado. Puesto que el resultado del dataframe resultante es la suma de los datos ofrecidos tanto por el Puerto de Los Angeles como el de Long Beach, se va acudir a las fuentes originarias para observar si el error está originado allí:\n",
    "- https://www.portoflosangeles.org/business/statistics/container-statistics/historical-teu-statistics-2020:\n",
    "292,762.25 \t423,678.75 \t889.,748.15 -> Hay un error de formato en la columna TEUs.\n",
    "- Para el caso de Long Beach, el formato es correcto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dado que ahora conocemos tanto el origen del error como el valor resultante, se va modificar el valor de 'Total TEUs' en la fila 25:\n",
    "GLA_data.loc[25, 'Total TEUs'] = GLA_data['Total Imports'].iloc[25] + GLA_data['Total Exports'].iloc[25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_line, labs, theme_minimal\n",
    "\n",
    "# Melt the dataframe to long format for easier plotting with plotnine\n",
    "GLA_data_melted = GLA_data_transformed_df.melt(id_vars=['Date'], value_vars=['Loaded Imports', 'Sum_of_Counts', 'Total Exports', 'Total Imports', 'Total TEUs'], var_name='Variable', value_name='Value')\n",
    "\n",
    "# Create the plot\n",
    "plot = (ggplot(GLA_data_melted, aes(x='Date', y='Value', color='Variable'))\n",
    "    + geom_line()\n",
    "    + labs(title='Time Series of Various Metrics',\n",
    "           x='Date',\n",
    "           y='Value')\n",
    "    + theme_538())\n",
    "\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A primera vista, se observa un más que probable outlier en 'Total TEUs'. Se van realizar distintas visualizaciones para esta variable: boxplot, diagrama scatter..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import ggplot, aes, geom_boxplot, geom_point, geom_histogram, stat_qq, stat_qq_line, labs, theme_minimal\n",
    "\n",
    "# Boxplot for 'Total TEUs'\n",
    "boxplot = (ggplot(GLA_data_transformed_df, aes(x=1, y='Total TEUs'))\n",
    "           + geom_boxplot()\n",
    "           + labs(title='Boxplot of Total TEUs', x='', y='Total TEUs')\n",
    "           + theme_538())\n",
    "\n",
    "boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# QQ plot for 'Total TEUs'\n",
    "qq_plot = (ggplot(GLA_data_transformed_df, aes(sample='Total TEUs'))\n",
    "           + stat_qq()\n",
    "           + stat_qq_line()\n",
    "           + labs(title='QQ Plot of Total TEUs', x='Theoretical Quantiles', y='Sample Quantiles')\n",
    "           + theme_538())\n",
    "\n",
    "qq_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram for 'Total TEUs'\n",
    "histogram = (ggplot(GLA_data_transformed_df, aes(x='Total TEUs'))\n",
    "             + geom_histogram(bins=30, fill='blue', color='black')\n",
    "             + labs(title='Histogram of Total TEUs', x='Total TEUs', y='Frequency')\n",
    "             + theme_538())\n",
    "\n",
    "histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Queda claro que ese valor es un outlier. ¿Pero qué hacer? ¿Cómo se ha llegado hasta él? No hay muchos datos y quizá eliminar toda esa fila de datos no fuera necesario. Así que voy a ver si originalmente existía tal dato y cómo se llegó a él."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the index of the maximum value in 'Total TEUs'\n",
    "max_teus_index = GLA_data['Total TEUs'].idxmax()\n",
    "\n",
    "# Get the 'Date' value for this index\n",
    "max_teus_date = GLA_data.loc[max_teus_index, 'Date']\n",
    "\n",
    "# Print the index and the 'Date' value\n",
    "print(f\"Index: {max_teus_index}, Date: {max_teus_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras arreglar ese dato, se va a proceder a tratar los outliers en el resto de variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLA_data_transformed_df.to_csv('../sources/GreaterLosAngeles_data_transformed.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puertos de Seattle y Tacoma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_836675/635753196.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  nwsa_teu_data['Unnamed: 0'].fillna(method='ffill', inplace=True)\n",
      "/tmp/ipykernel_836675/635753196.py:9: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  nwsa_teu_data['Unnamed: 0'].fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Read the Excel file and create a dataframe using the third row as the header\n",
    "nwsa_teu_data = pd.read_excel('../sources/NWSA Historical Cargo Stats.xls', sheet_name='TEUs', header=2)\n",
    "\n",
    "# Drop specific rows\n",
    "rows_to_drop = [11, 19, 27, 35, 43, 51, 59, 67, 75, 83, 91] + list(range(99, len(nwsa_teu_data)))\n",
    "nwsa_teu_data.drop(rows_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "nwsa_teu_data['Unnamed: 0'].fillna(method='ffill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the dataframe to long format\n",
    "nwsa_teu_data_long = nwsa_teu_data.melt(id_vars=['Unnamed: 0', 'Unnamed: 1'], value_vars=[2017, 2018, 2019, 2020, 2021, 2022, 2023, 2024], \n",
    "                                        var_name='Year', value_name='TEUs')\n",
    "# Rename 'Unnamed: 0' to 'Category' and 'Unnamed: 1' to 'Subcategory'\n",
    "nwsa_teu_data_long.rename(columns={'Unnamed: 0': 'Category', 'Unnamed: 1': 'Subcategory'}, inplace=True)\n",
    "rows_to_remove = nwsa_teu_data_long.loc[nwsa_teu_data_long[\"Category\"] == \"Total\"]\n",
    "\n",
    "# Remove rows using the indices from rows_to_remove\n",
    "nwsa_teu_data_long.drop(rows_to_remove.index, inplace=True)\n",
    "\n",
    "# Reset the index after dropping rows\n",
    "nwsa_teu_data_long.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Merge column 'Year' with 'Category' and call it 'Date'\n",
    "nwsa_teu_data_long['Date'] = pd.to_datetime(nwsa_teu_data_long['Year'].astype(str) + '-' + nwsa_teu_data_long['Category'], format='%Y-%b')\n",
    "\n",
    "# Drop columns 'Category' and 'Year'\n",
    "nwsa_teu_data_long.drop(columns=['Category', 'Year'], inplace=True)\n",
    "\n",
    "# Transform Date type to format '%Y-%m'\n",
    "nwsa_teu_data_long['Date'] = nwsa_teu_data_long['Date'].dt.strftime('%Y-%m')\n",
    "\n",
    "# Drop rows with NaN values in the 'Subcategory' column\n",
    "nwsa_teu_data_long.dropna(subset=['Subcategory'], inplace=True)\n",
    "\n",
    "# Pivot the dataframe\n",
    "nwsa_teu_data_pivot = nwsa_teu_data_long.pivot(index='Date', columns='Subcategory', values='TEUs').reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to sum\n",
    "columns_to_sum = ['Domestic - Alaska', 'Domestic - Hawaii', 'International Exports Full', 'International Imports Empty', 'International Imports Full']\n",
    "\n",
    "# Calculate the sum of the specified columns\n",
    "nwsa_teu_data_pivot['Sum_Other_Columns'] = nwsa_teu_data_pivot[columns_to_sum].sum(axis=1)\n",
    "\n",
    "# Impute NaN values in 'International Exports Empty'\n",
    "nwsa_teu_data_pivot['International Exports Empty'] = nwsa_teu_data_pivot.apply(\n",
    "    lambda row: row['Total TEUs'] - row['Sum_Other_Columns'] if pd.isna(row['International Exports Empty']) else row['International Exports Empty'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Drop the temporary 'Sum_Other_Columns' column\n",
    "nwsa_teu_data_pivot.drop(columns=['Sum_Other_Columns'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluir datos de incautacion para Seattle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Filter the dataframe for 'Los Angeles Field Office'\n",
    "    # df_filtered = df[df['Area of Responsibility'] == 'SEATTLE FIELD OFFICE']\n",
    "    \n",
    "    # Append the filtered dataframe to the list\n",
    "    drug_seizures_dataframes.append(df)\n",
    "\n",
    "# Concatenate all filtered dataframes into a single dataframe\n",
    "drug_seizures_combined = pd.concat(drug_seizures_dataframes, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "drug_seizures_combined.drop_duplicates(inplace=True)\n",
    "drug_seizures_combined = drug_seizures_combined.loc[drug_seizures_combined['Area of Responsibility'] == 'SEATTLE FIELD OFFICE']\n",
    "drug_seizures_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure all values in 'FY' column are strings\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].astype(str)\n",
    "\n",
    "# Replace ' (FYTD)' with an empty string\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].str.replace(' (FYTD)', '', regex=False)\n",
    "\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['FY'] + '-' + drug_seizures_combined['Month (abbv)'].astype(str)\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['Date'].str.replace(r'-(\\w{3})$', lambda x: '-' + x.group(1).capitalize(), regex=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format and then to '%Y-%m'\n",
    "drug_seizures_combined['Date'] = pd.to_datetime(drug_seizures_combined['Date'], format='%Y-%b').dt.strftime('%Y-%m')\n",
    "\n",
    "# Drop the original 'FY' and 'Month (abbv)' columns if no longer needed\n",
    "drug_seizures_combined.drop(columns=['FY', 'Month (abbv)', 'Component', 'Region', 'Land Filter', 'Area of Responsibility'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La sustitución de 'Area of Responsibility' por las coordenadas de latitud y longitud es una suerte de tratamiento de una variable categórica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Drug Type</th>\n",
       "      <th>Count of Event</th>\n",
       "      <th>Sum Qty (lbs)</th>\n",
       "      <th>Date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cocaine</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>47.449355</td>\n",
       "      <td>-122.428779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ecstasy</td>\n",
       "      <td>2</td>\n",
       "      <td>22.822253</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>47.449355</td>\n",
       "      <td>-122.428779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lsd</td>\n",
       "      <td>1</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>47.449355</td>\n",
       "      <td>-122.428779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Marijuana</td>\n",
       "      <td>63</td>\n",
       "      <td>2.769778</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>47.449355</td>\n",
       "      <td>-122.428779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Methamphetamine</td>\n",
       "      <td>2</td>\n",
       "      <td>0.038140</td>\n",
       "      <td>2019-04</td>\n",
       "      <td>47.449355</td>\n",
       "      <td>-122.428779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Drug Type  Count of Event  Sum Qty (lbs)     Date   latitude  \\\n",
       "0          Cocaine               1       0.003527  2019-04  47.449355   \n",
       "1          Ecstasy               2      22.822253  2019-04  47.449355   \n",
       "2              Lsd               1       0.017152  2019-04  47.449355   \n",
       "3        Marijuana              63       2.769778  2019-04  47.449355   \n",
       "4  Methamphetamine               2       0.038140  2019-04  47.449355   \n",
       "\n",
       "    longitude  \n",
       "0 -122.428779  \n",
       "1 -122.428779  \n",
       "2 -122.428779  \n",
       "3 -122.428779  \n",
       "4 -122.428779  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# row 25: Seattle/Tacoma, WA\n",
    "drug_seizures_combined['latitude'] = us_port_hubs.loc[25, 'coord_0']\n",
    "drug_seizures_combined['longitude'] = us_port_hubs.loc[25, 'coord_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe = drug_seizures_combined[['Drug Type', 'Count of Event', 'Sum Qty (lbs)']]\n",
    "drug_seizures_wide = pd.pivot_table(drug_seizures_combined, index=['Date','latitude','longitude'], columns='Drug Type', values=['Count of Event', 'Sum Qty (lbs)'], aggfunc='sum')\n",
    "drug_seizures_wide.columns = ['_'.join(col).strip() for col in drug_seizures_wide.columns.values]\n",
    "drug_seizures_wide.reset_index(inplace=True)\n",
    "drug_seizures_wide['Sum_of_Counts'] = drug_seizures_wide.filter(like='Count of Event_').sum(axis=1)\n",
    "# Adjust the dates for 'October', 'November', and 'December' by anticipating one year\n",
    "def adjust_fiscal_year(date_str):\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m')\n",
    "    if date.month in [10, 11, 12]:\n",
    "        date = date + pd.DateOffset(years=-1)\n",
    "    return date.strftime('%Y-%m')\n",
    "\n",
    "# Apply the adjustment to the 'Date' column in combined_teu_data\n",
    "drug_seizures_wide['Date'] = drug_seizures_wide['Date'].apply(adjust_fiscal_year)\n",
    "drug_seizures_wide.sort_values(by='Date', ascending=True, inplace=True)\n",
    "drug_seizures_wide.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificar dataframe de contenedores de Seattle:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['Date', 'Loaded Imports', 'Empty Imports', 'Total Imports',\n",
    "       'Loaded Exports', 'Empty Exports', 'Total Exports', 'Total TEUs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Subcategory</th>\n",
       "      <th>Date</th>\n",
       "      <th>Domestic - Alaska</th>\n",
       "      <th>Domestic - Hawaii</th>\n",
       "      <th>Empty Exports</th>\n",
       "      <th>Loaded Exports</th>\n",
       "      <th>Empty Imports</th>\n",
       "      <th>Loaded Imports</th>\n",
       "      <th>Total TEUs</th>\n",
       "      <th>Total Imports</th>\n",
       "      <th>Total Exports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-01</td>\n",
       "      <td>42223.00</td>\n",
       "      <td>9030.0</td>\n",
       "      <td>34268.0</td>\n",
       "      <td>77069.5</td>\n",
       "      <td>10304.7</td>\n",
       "      <td>128237.0</td>\n",
       "      <td>301174.20</td>\n",
       "      <td>138541.7</td>\n",
       "      <td>111337.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-02</td>\n",
       "      <td>38348.55</td>\n",
       "      <td>7815.0</td>\n",
       "      <td>36038.0</td>\n",
       "      <td>71243.0</td>\n",
       "      <td>7576.5</td>\n",
       "      <td>102697.0</td>\n",
       "      <td>263718.05</td>\n",
       "      <td>110273.5</td>\n",
       "      <td>107281.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-03</td>\n",
       "      <td>49332.95</td>\n",
       "      <td>11691.0</td>\n",
       "      <td>39149.0</td>\n",
       "      <td>99603.0</td>\n",
       "      <td>14679.0</td>\n",
       "      <td>120018.0</td>\n",
       "      <td>334472.95</td>\n",
       "      <td>134697.0</td>\n",
       "      <td>138752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-04</td>\n",
       "      <td>46951.00</td>\n",
       "      <td>8828.0</td>\n",
       "      <td>31488.0</td>\n",
       "      <td>77558.0</td>\n",
       "      <td>7126.0</td>\n",
       "      <td>110821.0</td>\n",
       "      <td>282772.00</td>\n",
       "      <td>117947.0</td>\n",
       "      <td>109046.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05</td>\n",
       "      <td>54911.53</td>\n",
       "      <td>9846.0</td>\n",
       "      <td>47445.0</td>\n",
       "      <td>81190.0</td>\n",
       "      <td>14351.0</td>\n",
       "      <td>115837.0</td>\n",
       "      <td>323580.53</td>\n",
       "      <td>130188.0</td>\n",
       "      <td>128635.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Subcategory     Date  Domestic - Alaska  Domestic - Hawaii  Empty Exports  \\\n",
       "0            2017-01           42223.00             9030.0        34268.0   \n",
       "1            2017-02           38348.55             7815.0        36038.0   \n",
       "2            2017-03           49332.95            11691.0        39149.0   \n",
       "3            2017-04           46951.00             8828.0        31488.0   \n",
       "4            2017-05           54911.53             9846.0        47445.0   \n",
       "\n",
       "Subcategory  Loaded Exports  Empty Imports  Loaded Imports  Total TEUs  \\\n",
       "0                   77069.5        10304.7        128237.0   301174.20   \n",
       "1                   71243.0         7576.5        102697.0   263718.05   \n",
       "2                   99603.0        14679.0        120018.0   334472.95   \n",
       "3                   77558.0         7126.0        110821.0   282772.00   \n",
       "4                   81190.0        14351.0        115837.0   323580.53   \n",
       "\n",
       "Subcategory  Total Imports  Total Exports  \n",
       "0                 138541.7       111337.5  \n",
       "1                 110273.5       107281.0  \n",
       "2                 134697.0       138752.0  \n",
       "3                 117947.0       109046.0  \n",
       "4                 130188.0       128635.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nwsa_teu_data_pivot.rename(columns={\n",
    "    'International Imports Full': 'Loaded Imports',\n",
    "    'International Imports Empty': 'Empty Imports',\n",
    "    'International Exports Full': 'Loaded Exports',\n",
    "    'International Exports Empty': 'Empty Exports'\n",
    "}, inplace=True)\n",
    "\n",
    "# Create 'Total Imports' and 'Total Exports' columns\n",
    "nwsa_teu_data_pivot['Total Imports'] = nwsa_teu_data_pivot['Loaded Imports'] + nwsa_teu_data_pivot['Empty Imports']\n",
    "nwsa_teu_data_pivot['Total Exports'] = nwsa_teu_data_pivot['Loaded Exports'] + nwsa_teu_data_pivot['Empty Exports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "NSWA_data = pd.merge(nwsa_teu_data_pivot, drug_seizures_wide, on='Date', how='inner')\n",
    "NSWA_data.drop(columns=['Domestic - Alaska', 'Domestic - Hawaii'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acoplar el dataframe generado para Seattle con el generado para 'Gran Los Angeles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate NSWA_data with GLA_data\n",
    "combined_data = pd.concat([NSWA_data, GLA_data], ignore_index=True)\n",
    "combined_data['Date'] = pd.to_datetime(combined_data['Date'], format='%Y-%m').dt.strftime('%Y-%m')\n",
    "\n",
    "# Sort the combined dataframe by 'Date' in ascending order\n",
    "combined_data.sort_values(by='Date', ascending=True, inplace=True)\n",
    "\n",
    "# Reset the index of the sorted dataframe\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Empty Exports</th>\n",
       "      <th>Loaded Exports</th>\n",
       "      <th>Empty Imports</th>\n",
       "      <th>Loaded Imports</th>\n",
       "      <th>Total TEUs</th>\n",
       "      <th>Total Imports</th>\n",
       "      <th>Total Exports</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Sum Qty (lbs)_Ecstasy</th>\n",
       "      <th>Sum Qty (lbs)_Fentanyl</th>\n",
       "      <th>Sum Qty (lbs)_Heroin</th>\n",
       "      <th>Sum Qty (lbs)_Ketamine</th>\n",
       "      <th>Sum Qty (lbs)_Khat (Catha Edulis)</th>\n",
       "      <th>Sum Qty (lbs)_Lsd</th>\n",
       "      <th>Sum Qty (lbs)_Marijuana</th>\n",
       "      <th>Sum Qty (lbs)_Methamphetamine</th>\n",
       "      <th>Sum Qty (lbs)_Other Drugs**</th>\n",
       "      <th>Sum_of_Counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>2024-12</td>\n",
       "      <td>54572.75</td>\n",
       "      <td>65396.00</td>\n",
       "      <td>8174.0</td>\n",
       "      <td>118356.25</td>\n",
       "      <td>304747.69</td>\n",
       "      <td>126530.25</td>\n",
       "      <td>119968.75</td>\n",
       "      <td>47.449355</td>\n",
       "      <td>-122.428779</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063934</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.077382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009039</td>\n",
       "      <td>1275.361355</td>\n",
       "      <td>0.009678</td>\n",
       "      <td>2.842376</td>\n",
       "      <td>103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>2024-12</td>\n",
       "      <td>719025.50</td>\n",
       "      <td>209138.75</td>\n",
       "      <td>13622.0</td>\n",
       "      <td>932564.50</td>\n",
       "      <td>1874349.75</td>\n",
       "      <td>946186.50</td>\n",
       "      <td>928164.25</td>\n",
       "      <td>33.804338</td>\n",
       "      <td>-118.379055</td>\n",
       "      <td>...</td>\n",
       "      <td>16.437887</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15.199550</td>\n",
       "      <td>54.079393</td>\n",
       "      <td>0.019401</td>\n",
       "      <td>898.238874</td>\n",
       "      <td>48.105306</td>\n",
       "      <td>604.207032</td>\n",
       "      <td>215.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Empty Exports  Loaded Exports  Empty Imports  Loaded Imports  \\\n",
       "148  2024-12       54572.75        65396.00         8174.0       118356.25   \n",
       "149  2024-12      719025.50       209138.75        13622.0       932564.50   \n",
       "\n",
       "     Total TEUs  Total Imports  Total Exports   latitude   longitude  ...  \\\n",
       "148   304747.69      126530.25      119968.75  47.449355 -122.428779  ...   \n",
       "149  1874349.75      946186.50      928164.25  33.804338 -118.379055  ...   \n",
       "\n",
       "     Sum Qty (lbs)_Ecstasy  Sum Qty (lbs)_Fentanyl  Sum Qty (lbs)_Heroin  \\\n",
       "148               0.063934                     NaN                   NaN   \n",
       "149              16.437887                     NaN                   NaN   \n",
       "\n",
       "     Sum Qty (lbs)_Ketamine  Sum Qty (lbs)_Khat (Catha Edulis)  \\\n",
       "148                0.077382                                NaN   \n",
       "149               15.199550                          54.079393   \n",
       "\n",
       "     Sum Qty (lbs)_Lsd  Sum Qty (lbs)_Marijuana  \\\n",
       "148           0.009039              1275.361355   \n",
       "149           0.019401               898.238874   \n",
       "\n",
       "     Sum Qty (lbs)_Methamphetamine  Sum Qty (lbs)_Other Drugs**  Sum_of_Counts  \n",
       "148                       0.009678                     2.842376          103.0  \n",
       "149                      48.105306                   604.207032          215.0  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.loc[combined_data['Date'] == '2024-12']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incluir puerto de San Diego:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aparentemente los datos en San Diego son muy pequeños para el tráfico de contenedores.\n",
    "Fuente: https://www.portofsandiego.org/maritime/cargo-and-trade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto de Oakland en la SFBA:\n",
    "\n",
    "Nota: The Port of Oakland handles 99% of the containerized goods moving through Northern California\n",
    "Fuente: https://vitalsigns.mtc.ca.gov/indicators/seaport-activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file and create a dataframe\n",
    "teu_data_oakland = pd.read_excel('../sources/TEUs_PortOakland_2025.xls', header=0)\n",
    "\n",
    "# Create the 'Date' column\n",
    "teu_data_oakland['Date'] = pd.concat([\n",
    "    pd.to_datetime(teu_data_oakland.loc[:26, 'Year'].astype(str) + '-' + teu_data_oakland.loc[:26, 'Month'], format='%Y-%B').dt.strftime('%Y-%m'),\n",
    "    pd.to_datetime(teu_data_oakland.loc[27:, 'Year'], format='%Y-%m').dt.strftime('%Y-%m')\n",
    "]).reset_index(drop=True)\n",
    "\n",
    "# Display the modified dataframe\n",
    "teu_data_oakland.drop(columns=['Year', 'Month', 'Total \\nFull', 'Total\\nEmpty'], inplace=True)\n",
    "teu_data_oakland.rename(columns={'Grand\\nTotal': 'Total TEUs',\n",
    "                                 'Import\\nFull':'Loaded Imports',\n",
    "                                 'Import\\nEmpty':'Empty Imports',\n",
    "                                 'Export \\nFull':'Loaded Exports',\n",
    "                                 'Export\\nEmpty':'Empty Exports',\n",
    "                                 }, inplace=True)\n",
    "\n",
    "teu_data_oakland['Total Imports'] = teu_data_oakland['Loaded Imports'] + teu_data_oakland['Empty Imports']\n",
    "teu_data_oakland['Total Exports'] = teu_data_oakland['Loaded Exports'] + teu_data_oakland['Empty Exports']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar set de datos de incautacion (incluir coordenadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Append the filtered dataframe to the list\n",
    "    drug_seizures_dataframes.append(df)\n",
    "\n",
    "# Concatenate all filtered dataframes into a single dataframe\n",
    "drug_seizures_combined = pd.concat(drug_seizures_dataframes, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "drug_seizures_combined.drop_duplicates(inplace=True)\n",
    "drug_seizures_combined = drug_seizures_combined.loc[drug_seizures_combined['Area of Responsibility'] == 'SAN FRANCISCO FIELD OFFICE']\n",
    "drug_seizures_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure all values in 'FY' column are strings\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].astype(str)\n",
    "\n",
    "# Replace ' (FYTD)' with an empty string\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].str.replace(' (FYTD)', '', regex=False)\n",
    "\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['FY'] + '-' + drug_seizures_combined['Month (abbv)'].astype(str)\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['Date'].str.replace(r'-(\\w{3})$', lambda x: '-' + x.group(1).capitalize(), regex=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format and then to '%Y-%m'\n",
    "drug_seizures_combined['Date'] = pd.to_datetime(drug_seizures_combined['Date'], format='%Y-%b').dt.strftime('%Y-%m')\n",
    "\n",
    "# Drop the original 'FY' and 'Month (abbv)' columns if no longer needed\n",
    "drug_seizures_combined.drop(columns=['FY', 'Month (abbv)', 'Component', 'Region', 'Land Filter', 'Area of Responsibility'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 13: SFBA, CA\n",
    "drug_seizures_combined['latitude'] = us_port_hubs.loc[13, 'coord_0']\n",
    "drug_seizures_combined['longitude'] = us_port_hubs.loc[13, 'coord_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe = drug_seizures_combined[['Drug Type', 'Count of Event', 'Sum Qty (lbs)']]\n",
    "drug_seizures_wide = pd.pivot_table(drug_seizures_combined, index=['Date','latitude','longitude'], columns='Drug Type', values=['Count of Event', 'Sum Qty (lbs)'], aggfunc='sum')\n",
    "drug_seizures_wide.columns = ['_'.join(col).strip() for col in drug_seizures_wide.columns.values]\n",
    "drug_seizures_wide.reset_index(inplace=True)\n",
    "drug_seizures_wide['Sum_of_Counts'] = drug_seizures_wide.filter(like='Count of Event_').sum(axis=1)\n",
    "# Adjust the dates for 'October', 'November', and 'December' by anticipating one year\n",
    "def adjust_fiscal_year(date_str):\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m')\n",
    "    if date.month in [10, 11, 12]:\n",
    "        date = date + pd.DateOffset(years=-1)\n",
    "    return date.strftime('%Y-%m')\n",
    "\n",
    "# Apply the adjustment to the 'Date' column in combined_teu_data\n",
    "drug_seizures_wide['Date'] = drug_seizures_wide['Date'].apply(adjust_fiscal_year)\n",
    "drug_seizures_wide.sort_values(by='Date', ascending=True, inplace=True)\n",
    "drug_seizures_wide.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join de los datos de contenedores con incautaciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "SFBA_data = pd.merge(teu_data_oakland, drug_seizures_wide, on='Date', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acoplar datos de 'San Francisco Bay Area'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate SFBA_data with combined_data\n",
    "combined_data = pd.concat([combined_data, SFBA_data], ignore_index=True)\n",
    "\n",
    "# Sort the combined dataframe by 'Date' in ascending order\n",
    "combined_data.sort_values(by='Date', ascending=True, inplace=True)\n",
    "\n",
    "# Reset the index of the sorted dataframe\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto de Newark/New York:\n",
    "Fuente: https://www.panynj.gov/port/en/our-port/facts-and-figures.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file and create a dataframe\n",
    "teu_data_newark = pd.read_excel('../sources/TEUs_PortNewark_2025.xls', header=0, thousands=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_data_newark['Date'] = pd.to_datetime(teu_data_newark['Unnamed: 0'].astype(str) + '-' + teu_data_newark['Unnamed: 1'], format='%Y-%B').dt.strftime('%Y-%m')\n",
    "teu_data_newark.drop(columns=['Unnamed: 0', 'Unnamed: 1'], inplace=True)\n",
    "\n",
    "teu_data_newark.rename(columns={\n",
    "                                'Loads Import TEUs':'Loaded Imports',\n",
    "                                'Empties Import TEUs':'Empty Imports',\n",
    "                                'Loads Export TEUs':'Loaded Exports',\n",
    "                                'Empties Export TEUs':'Empty Exports'\n",
    "                                }, inplace=True)\n",
    "\n",
    "teu_data_newark['Total Imports'] = teu_data_newark['Loaded Imports'] + teu_data_newark['Empty Imports']\n",
    "teu_data_newark['Total Exports'] = teu_data_newark['Loaded Exports'] + teu_data_newark['Empty Exports']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar dataset de incautacion de drogas + coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Append the filtered dataframe to the list\n",
    "    drug_seizures_dataframes.append(df)\n",
    "\n",
    "# Concatenate all filtered dataframes into a single dataframe\n",
    "drug_seizures_combined = pd.concat(drug_seizures_dataframes, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "drug_seizures_combined.drop_duplicates(inplace=True)\n",
    "drug_seizures_combined = drug_seizures_combined.loc[drug_seizures_combined['Area of Responsibility'] == 'NEW YORK FIELD OFFICE']\n",
    "drug_seizures_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure all values in 'FY' column are strings\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].astype(str)\n",
    "\n",
    "# Replace ' (FYTD)' with an empty string\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].str.replace(' (FYTD)', '', regex=False)\n",
    "\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['FY'] + '-' + drug_seizures_combined['Month (abbv)'].astype(str)\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['Date'].str.replace(r'-(\\w{3})$', lambda x: '-' + x.group(1).capitalize(), regex=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format and then to '%Y-%m'\n",
    "drug_seizures_combined['Date'] = pd.to_datetime(drug_seizures_combined['Date'], format='%Y-%b').dt.strftime('%Y-%m')\n",
    "\n",
    "# Drop the original 'FY' and 'Month (abbv)' columns if no longer needed\n",
    "drug_seizures_combined.drop(columns=['FY', 'Month (abbv)', 'Component', 'Region', 'Land Filter', 'Area of Responsibility'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 6: NJ/NY\n",
    "drug_seizures_combined['latitude'] = us_port_hubs.loc[6, 'coord_0']\n",
    "drug_seizures_combined['longitude'] = us_port_hubs.loc[6, 'coord_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe = drug_seizures_combined[['Drug Type', 'Count of Event', 'Sum Qty (lbs)']]\n",
    "drug_seizures_wide = pd.pivot_table(drug_seizures_combined, index=['Date','latitude','longitude'], columns='Drug Type', values=['Count of Event', 'Sum Qty (lbs)'], aggfunc='sum')\n",
    "drug_seizures_wide.columns = ['_'.join(col).strip() for col in drug_seizures_wide.columns.values]\n",
    "drug_seizures_wide.reset_index(inplace=True)\n",
    "drug_seizures_wide['Sum_of_Counts'] = drug_seizures_wide.filter(like='Count of Event_').sum(axis=1)\n",
    "# Adjust the dates for 'October', 'November', and 'December' by anticipating one year\n",
    "def adjust_fiscal_year(date_str):\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m')\n",
    "    if date.month in [10, 11, 12]:\n",
    "        date = date + pd.DateOffset(years=-1)\n",
    "    return date.strftime('%Y-%m')\n",
    "\n",
    "# Apply the adjustment to the 'Date' column in combined_teu_data\n",
    "drug_seizures_wide['Date'] = drug_seizures_wide['Date'].apply(adjust_fiscal_year)\n",
    "drug_seizures_wide.sort_values(by='Date', ascending=True, inplace=True)\n",
    "drug_seizures_wide.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer join entre contenedores e incautaciones en Newark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "NJNY_data = pd.merge(teu_data_newark, drug_seizures_wide, on='Date', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acoplar los datos de Newark al resto del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate SFBA_data with combined_data\n",
    "combined_data = pd.concat([combined_data, NJNY_data], ignore_index=True)\n",
    "\n",
    "# Sort the combined dataframe by 'Date' in ascending order\n",
    "combined_data.sort_values(by='Date', ascending=True, inplace=True)\n",
    "\n",
    "# Reset the index of the sorted dataframe\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto de Houston:\n",
    "- En primer lugar se aplicarán los datos del puerto de Houston.\n",
    "- Otros: beaumont, texas city, port freeport, port arthur, galveston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file and create a dataframe\n",
    "houston_teu_data = pd.read_excel('../sources/Container-Volume-TEU-stats-in-depth-January-2025.xls', sheet_name='Port_Houston', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the dataframe\n",
    "houston_teu_data.drop(columns=['Loaded Total','Empty Total'], inplace=True)\n",
    "houston_teu_data.rename(columns={'Loaded and Empty\\nTotal': 'Total TEUs'}, inplace=True)\n",
    "houston_teu_data['Total Imports'] = houston_teu_data['Loaded Imports'] + houston_teu_data['Empty Imports']\n",
    "houston_teu_data['Total Exports'] = houston_teu_data['Loaded Exports'] + houston_teu_data['Empty Exports']\n",
    "houston_teu_data['Date'] = pd.to_datetime(houston_teu_data['Date'], format='%b‐%y').dt.strftime('%Y-%m')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar dataset de incautacion de drogas + coordenadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Append the filtered dataframe to the list\n",
    "    drug_seizures_dataframes.append(df)\n",
    "\n",
    "# Concatenate all filtered dataframes into a single dataframe\n",
    "drug_seizures_combined = pd.concat(drug_seizures_dataframes, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "drug_seizures_combined.drop_duplicates(inplace=True)\n",
    "drug_seizures_combined = drug_seizures_combined.loc[drug_seizures_combined['Area of Responsibility'] == 'HOUSTON FIELD OFFICE']\n",
    "drug_seizures_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure all values in 'FY' column are strings\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].astype(str)\n",
    "\n",
    "# Replace ' (FYTD)' with an empty string\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].str.replace(' (FYTD)', '', regex=False)\n",
    "\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['FY'] + '-' + drug_seizures_combined['Month (abbv)'].astype(str)\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['Date'].str.replace(r'-(\\w{3})$', lambda x: '-' + x.group(1).capitalize(), regex=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format and then to '%Y-%m'\n",
    "drug_seizures_combined['Date'] = pd.to_datetime(drug_seizures_combined['Date'], format='%Y-%b').dt.strftime('%Y-%m')\n",
    "\n",
    "# Drop the original 'FY' and 'Month (abbv)' columns if no longer needed\n",
    "drug_seizures_combined.drop(columns=['FY', 'Month (abbv)', 'Component', 'Region', 'Land Filter', 'Area of Responsibility'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 2: Houston/Galveston, TX\n",
    "drug_seizures_combined['latitude'] = us_port_hubs.loc[2, 'coord_0']\n",
    "drug_seizures_combined['longitude'] = us_port_hubs.loc[2, 'coord_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe = drug_seizures_combined[['Drug Type', 'Count of Event', 'Sum Qty (lbs)']]\n",
    "drug_seizures_wide = pd.pivot_table(drug_seizures_combined, index=['Date','latitude','longitude'], columns='Drug Type', values=['Count of Event', 'Sum Qty (lbs)'], aggfunc='sum')\n",
    "drug_seizures_wide.columns = ['_'.join(col).strip() for col in drug_seizures_wide.columns.values]\n",
    "drug_seizures_wide.reset_index(inplace=True)\n",
    "drug_seizures_wide['Sum_of_Counts'] = drug_seizures_wide.filter(like='Count of Event_').sum(axis=1)\n",
    "# Adjust the dates for 'October', 'November', and 'December' by anticipating one year\n",
    "def adjust_fiscal_year(date_str):\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m')\n",
    "    if date.month in [10, 11, 12]:\n",
    "        date = date + pd.DateOffset(years=-1)\n",
    "    return date.strftime('%Y-%m')\n",
    "\n",
    "# Apply the adjustment to the 'Date' column in combined_teu_data\n",
    "drug_seizures_wide['Date'] = drug_seizures_wide['Date'].apply(adjust_fiscal_year)\n",
    "drug_seizures_wide.sort_values(by='Date', ascending=True, inplace=True)\n",
    "drug_seizures_wide.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer join entre contenedores e incautaciones en Houston:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Houston_data = pd.merge(houston_teu_data, drug_seizures_wide, on='Date', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acoplar los datos de Houston al resto del dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate SFBA_data with combined_data\n",
    "combined_data = pd.concat([combined_data, Houston_data], ignore_index=True)\n",
    "\n",
    "# Sort the combined dataframe by 'Date' in ascending order\n",
    "combined_data.sort_values(by='Date', ascending=True, inplace=True)\n",
    "\n",
    "# Reset the index of the sorted dataframe\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puerto de Miami/Fort Lauderdale:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir el dataset:\n",
    "- https://www.porteverglades.net/\n",
    "- https://assets.simpleviewinc.com/simpleview/image/upload/v1/clients/porteverglades/January_Monthly_Loaded_TEUs_02_13_2025_9e6f70c1-032a-4bbc-8f69-2d027dcfa394.pdf\n",
    "- https://assets.simpleviewinc.com/simpleview/image/upload/v1/clients/porteverglades/FY2023_September_TEUS_Loaded_by_Month_7065b619-cddd-4b97-a02c-8c247c743ac0.pdf\n",
    "- https://assets.simpleviewinc.com/simpleview/image/upload/v1/clients/porteverglades/August_TEUS_Loaded_by_Month_Fiscal_2020_Calander_2020_9439e3f7-7154-4030-a9b8-9ec592a57fde.pdf\n",
    "\n",
    "- https://assets.simpleviewinc.com/simpleview/image/upload/v1/clients/porteverglades/Preliminary_Waterborne_Commerce_Chart_2024__1a6b16e6-94b2-46ac-89e7-d7080779f346.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datos de Port Everglades, FL (Puerto de Fort Lauderdale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file and create a dataframe\n",
    "teu_data_everglades = pd.read_excel('../sources/TEUs_PortEverglades_2025.xls', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display rows with NaN values in teu_data_everglades\n",
    "teu_data_everglades[teu_data_everglades.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se observa que faltan los últimos meses del año fiscal 2021. Sin embargo, se tienen los datos totales para cada año fiscal. Estos missing values se van a tratar de inferir a partir del contexto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file and specify the header row\n",
    "file_path = '../sources/Preliminary_Waterborne_Commerce_Chart_2024__1a6b16e6-94b2-46ac-89e7-d7080779f346.xls'\n",
    "df = pd.read_excel(file_path, header=1, usecols='A:G')\n",
    "\n",
    "# Extract rows 23 and 24 (note that pandas uses 0-based indexing, so we need to adjust the row numbers)\n",
    "extracted_rows = df.iloc[20:22]\n",
    "\n",
    "# Display the extracted rows\n",
    "extracted_rows = extracted_rows.T\n",
    "\n",
    "# Reset the index and set the first row as the header\n",
    "extracted_rows.columns = extracted_rows.iloc[0]\n",
    "extracted_rows = extracted_rows[1:]\n",
    "\n",
    "extracted_rows = extracted_rows[::-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para asegurarse de que los datos anuales son, prácticamente, coincidentes con la suma de los mensuales, se va a proceder a su cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the dataframe by every 12 rows and sum the 'Loaded Exports' and 'Loaded Imports' columns\n",
    "grouped_sums = teu_data_everglades.groupby(teu_data_everglades.index // 12)[['Loaded Exports', 'Loaded Imports']].sum()\n",
    "grouped_sums['TEUs Loaded'] = grouped_sums['Loaded Exports'] + grouped_sums['Loaded Imports']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new dataframe with 'grouped_sums['TEUs Loaded']' and 'extracted_rows['TEUs Loaded']'\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Grouped TEUs Loaded': grouped_sums['TEUs Loaded'].values[:6],\n",
    "    'Extracted TEUs Loaded': extracted_rows['TEUs Loaded'].astype(float).values\n",
    "})\n",
    "\n",
    "# Add a new column that is the difference between both columns\n",
    "comparison_df['Difference'] = comparison_df['Grouped TEUs Loaded'] - comparison_df['Extracted TEUs Loaded']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar los datos mensuales con los datos anuales:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el año 2021, faltan 3 meses (NAs) pero se tienen los datos de 'Total Loaded' y 'Total TEUs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_data_everglades.iloc[24:36].to_csv('../sources/TEUs_PortEverglades_2023_FY.csv', index=False, sep=',')\n",
    "everglades_2021 = pd.read_csv('../sources/TEUs_PortEverglades_2023_FY.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute proportions\n",
    "prop_imports = everglades_2021['Loaded Imports'].sum(skipna=True) / (everglades_2021['Loaded Imports'].sum(skipna=True) + everglades_2021['Loaded Exports'].sum(skipna=True))\n",
    "prop_exports = 1 - prop_imports\n",
    "\n",
    "# Compute missing values\n",
    "missing_total = 186169\n",
    "impute_value_imports = round((missing_total * prop_imports) / everglades_2021['Loaded Imports'].isna().sum())\n",
    "impute_value_exports = round((missing_total * prop_exports) / everglades_2021['Loaded Exports'].isna().sum())\n",
    "\n",
    "# Impute missing values\n",
    "everglades_2021.loc[everglades_2021['Loaded Imports'].isna(), 'Loaded Imports'] = impute_value_imports\n",
    "everglades_2021.loc[everglades_2021['Loaded Exports'].isna(), 'Loaded Exports'] = impute_value_exports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputar ahora el resto de valores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76191.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_rows['TEUs Empty'] = extracted_rows['TEUs Total'] - extracted_rows['TEUs Loaded']\n",
    "emptys_2021 = everglades_2021['Empty Imports'].sum(skipna=True) + everglades_2021['Empty Exports'].sum(skipna=True)\n",
    "extracted_rows.loc[2021]['TEUs Empty'] - emptys_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute proportions\n",
    "prop_imports = everglades_2021['Empty Imports'].sum(skipna=True) / (everglades_2021['Empty Imports'].sum(skipna=True) + everglades_2021['Empty Exports'].sum(skipna=True))\n",
    "prop_exports = 1 - prop_imports\n",
    "\n",
    "# Compute missing values\n",
    "missing_total = extracted_rows.loc[2021]['TEUs Empty'] - emptys_2021\n",
    "impute_value_imports = round((missing_total * prop_imports) / everglades_2021['Empty Imports'].isna().sum())\n",
    "impute_value_exports = round((missing_total * prop_exports) / everglades_2021['Empty Exports'].isna().sum())\n",
    "\n",
    "# Impute missing values\n",
    "everglades_2021.loc[everglades_2021['Empty Imports'].isna(), 'Empty Imports'] = impute_value_imports\n",
    "everglades_2021.loc[everglades_2021['Empty Exports'].isna(), 'Empty Exports'] = impute_value_exports\n",
    "\n",
    "# Update 'Total Imports', 'Total Exports', and 'Total TEUs' for rows 9 to 11 in 'everglades_2021'\n",
    "everglades_2021.loc[9:11, 'Total Imports'] = everglades_2021.loc[9:11, 'Empty Imports'] + everglades_2021.loc[9:11, 'Loaded Imports']\n",
    "everglades_2021.loc[9:11, 'Total Exports'] = everglades_2021.loc[9:11, 'Empty Exports'] + everglades_2021.loc[9:11, 'Loaded Exports']\n",
    "everglades_2021.loc[9:11, 'Total TEUs'] = everglades_2021.loc[9:11, 'Total Imports'] + everglades_2021.loc[9:11, 'Total Exports']\n",
    "\n",
    "# Imputar valores a las filas con NAs del dataframe de teu_data_everglades:\n",
    "teu_data_everglades[33:36] = everglades_2021[9:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez cubiertos los missing values toca revisar que las columnas coinciden con lo esperado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "teu_data_everglades.rename(columns={'Unnamed: 0': 'Date'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generar dataset de incautacion de drogas + coordenadas para el puerto de Fort Lauderdale/Everglades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each CSV file\n",
    "for file in csv_files:\n",
    "    # Read the CSV file into a pandas dataframe\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # Append the filtered dataframe to the list\n",
    "    drug_seizures_dataframes.append(df)\n",
    "\n",
    "# Concatenate all filtered dataframes into a single dataframe\n",
    "drug_seizures_combined = pd.concat(drug_seizures_dataframes, ignore_index=True)\n",
    "\n",
    "# Drop duplicates\n",
    "drug_seizures_combined.drop_duplicates(inplace=True)\n",
    "drug_seizures_combined = drug_seizures_combined.loc[drug_seizures_combined['Area of Responsibility'] == 'MIAMI FIELD OFFICE']\n",
    "drug_seizures_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ensure all values in 'FY' column are strings\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].astype(str)\n",
    "\n",
    "# Replace ' (FYTD)' with an empty string\n",
    "drug_seizures_combined['FY'] = drug_seizures_combined['FY'].str.replace(' (FYTD)', '', regex=False)\n",
    "\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['FY'] + '-' + drug_seizures_combined['Month (abbv)'].astype(str)\n",
    "drug_seizures_combined['Date'] = drug_seizures_combined['Date'].str.replace(r'-(\\w{3})$', lambda x: '-' + x.group(1).capitalize(), regex=True)\n",
    "\n",
    "# Convert 'Date' column to datetime format and then to '%Y-%m'\n",
    "drug_seizures_combined['Date'] = pd.to_datetime(drug_seizures_combined['Date'], format='%Y-%b').dt.strftime('%Y-%m')\n",
    "\n",
    "# Drop the original 'FY' and 'Month (abbv)' columns if no longer needed\n",
    "drug_seizures_combined.drop(columns=['FY', 'Month (abbv)', 'Component', 'Region', 'Land Filter', 'Area of Responsibility'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row 9: Miami-Fort Lauderdale, FL\n",
    "drug_seizures_combined['latitude'] = us_port_hubs.loc[9, 'coord_0']\n",
    "drug_seizures_combined['longitude'] = us_port_hubs.loc[9, 'coord_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subdataframe = drug_seizures_combined[['Drug Type', 'Count of Event', 'Sum Qty (lbs)']]\n",
    "drug_seizures_wide = pd.pivot_table(drug_seizures_combined, index=['Date','latitude','longitude'], columns='Drug Type', values=['Count of Event', 'Sum Qty (lbs)'], aggfunc='sum')\n",
    "drug_seizures_wide.columns = ['_'.join(col).strip() for col in drug_seizures_wide.columns.values]\n",
    "drug_seizures_wide.reset_index(inplace=True)\n",
    "drug_seizures_wide['Sum_of_Counts'] = drug_seizures_wide.filter(like='Count of Event_').sum(axis=1)\n",
    "# Adjust the dates for 'October', 'November', and 'December' by anticipating one year\n",
    "def adjust_fiscal_year(date_str):\n",
    "    date = pd.to_datetime(date_str, format='%Y-%m')\n",
    "    if date.month in [10, 11, 12]:\n",
    "        date = date + pd.DateOffset(years=-1)\n",
    "    return date.strftime('%Y-%m')\n",
    "\n",
    "# Apply the adjustment to the 'Date' column in combined_teu_data\n",
    "drug_seizures_wide['Date'] = drug_seizures_wide['Date'].apply(adjust_fiscal_year)\n",
    "drug_seizures_wide.sort_values(by='Date', ascending=True, inplace=True)\n",
    "drug_seizures_wide.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacer join entre contenedores e incautaciones en Houston:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Miami_data = pd.merge(teu_data_everglades, drug_seizures_wide, on='Date', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate Miami_data with combined_data\n",
    "combined_data = pd.concat([combined_data, Miami_data], ignore_index=True)\n",
    "\n",
    "# Sort the combined dataframe by 'Date' in ascending order\n",
    "combined_data.sort_values(by='Date', ascending=True, inplace=True)\n",
    "\n",
    "# Reset the index of the sorted dataframe\n",
    "combined_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resumen y otros puertos posibles\n",
    "- San Diego\n",
    "- Nueva Orleans\n",
    "- Tampa *\n",
    "- Savannah **\n",
    "- Boston *\n",
    "- Chicago\n",
    "- Corpus Christi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_csv('../sources/six_ports_USA_drugs.csv', index=False, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Incluir la variación de población en Áreas Metropolitanas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaciones:\n",
    "- Comparar series temporales\n",
    "- Comparar volumen según posición geográfica\n",
    "- Una serie temporal por el target\n",
    "- Comparar tipos de target\n",
    "- Análisis de variables por puerto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Empty Exports', 'Loaded Exports', 'Empty Imports',\n",
       "       'Loaded Imports', 'Total TEUs', 'Total Imports', 'Total Exports',\n",
       "       'latitude', 'longitude', 'Count of Event_Cocaine',\n",
       "       'Count of Event_Ecstasy', 'Count of Event_Fentanyl',\n",
       "       'Count of Event_Heroin', 'Count of Event_Ketamine',\n",
       "       'Count of Event_Khat (Catha Edulis)', 'Count of Event_Lsd',\n",
       "       'Count of Event_Marijuana', 'Count of Event_Methamphetamine',\n",
       "       'Count of Event_Other Drugs**', 'Sum Qty (lbs)_Cocaine',\n",
       "       'Sum Qty (lbs)_Ecstasy', 'Sum Qty (lbs)_Fentanyl',\n",
       "       'Sum Qty (lbs)_Heroin', 'Sum Qty (lbs)_Ketamine',\n",
       "       'Sum Qty (lbs)_Khat (Catha Edulis)', 'Sum Qty (lbs)_Lsd',\n",
       "       'Sum Qty (lbs)_Marijuana', 'Sum Qty (lbs)_Methamphetamine',\n",
       "       'Sum Qty (lbs)_Other Drugs**', 'Sum_of_Counts'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
